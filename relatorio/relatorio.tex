\documentclass[12pt]{article}

% Fonte com acentos
\usepackage[brazil]{babel} \usepackage[utf8]{inputenc} \usepackage[T1]{fontenc}
\usepackage[lighttt]{lmodern} \usepackage[top=1.4in, bottom=1in, left=1in,
right=1in]{geometry} \usepackage{graphicx} % para adicionar imagem
\usepackage{listings} \usepackage{amsmath} \usepackage{indentfirst}
\usepackage{multicol}

\begin{document}

\setlength{\parskip}{0.2cm}

\title{Análise de código e eficiência do método do Gradiente}

\author{Aryane Ast dos Santos\\ Kevin Katzer}

\date{23 de novembro de 2014}

\maketitle

\tableofcontents

\pagebreak

\section{Introdução}
Motivação...

\section{Verificação de uso de memória com Valgrind}\label{sec:Valgrind}

Ao executar a ferramenta Valgrind para se obter informações sobre vazamento de
memória no programa gradSolver, foi possível observar 5 erros, todos em
contextos diferentes, além de 16 allocações e apenas 2 liberações de memória.

Os resultados da execução do programa são parcialmente apresentados na
figura~\ref{fig:valgrindOut}.

\begin{figure}[htb]
\begin{tt}\noindent
==29599== Command: ./gradSolver -r 5\\
==28949== HEAP SUMMARY:\\
==28949==     in use at exit: 560 bytes in 14 blocks\\
==28949==   total heap usage: 16 allocs, 2 frees, 800 bytes allocated\\
==28949== LEAK SUMMARY:\\
==28949==    definitely lost: 560 bytes in 14 blocks\\
==28949== ERROR SUMMARY: 5 errors from 5 contexts (suppressed: 0 from 0)
\end{tt}\caption{Saída do Valgrind}\label{fig:valgrindOut}
\end{figure}

Aqui o gradSolver foi executado com uma matriz quadrada de ordem 5, porém os
mesmos problemas listados na figura~\ref{fig:valgrindOut} são encontrados em
execuções de matrizes de qualquer dimensão. E de maneira análoga, ao resolver os
problemas apresentados, numa execução com matriz maior, eles ficam também
automaticamente resolvidos.

Para contornar os vazamentos de memória encontrados, foi necessário liberar a
memória dos vetores alocados explicitamente como o vetor x na função main, o
vetor aux em calcGrad e o vetor r de resíduo na função gradSolver. Além disso,
no main, foram adicionados frees para os ponteiros para char das flags do
getopt.

\section{Arquitetura do computador}\label{sec:likwid}

Utilizando a ferramenta likwid-topology, é possível obter as seguintes
informações sobre a arquitetura do computador utilizado para os testes de
performance.

\begin{figure}[ht]\footnotesize
\begin{tt}
\begin{multicols}{2}
CPU type:	AMD Magny Cours processor\\
Hardware Thread Topology\\
Sockets:	4\\
Cores per socket:	8\\
Threads per core:	1\\
Socket 0: ( 0 1 2 3 4 5 6 7 )\\
\\
\\
NUMA Topology\\
NUMA domains: 2\\
Domain 0:\\
Processors: 0 1 2 3 4 5 12 13 14 15 16 17\\
Relative distance to nodes: 10 21\\
Memory: 2403.31MB free of total 24103.8MB\\
\end{multicols}
\begin{multicols}{3}
Cache Topology\\
Level:	1\\
Size:	64 kB\\
Type:	Data cache\\
Associativity:	2\\
Number of sets:	512\\
Cache line size:64\\
Non Inclusive cache\\
Shared among 1 threads\\
Level:	2\\
Size:	512 kB\\
Type:	Unified cache\\
Associativity:	16\\
Number of sets:	512\\
Cache line size:64\\
Non Inclusive cache\\\
Shared among 1 threads\\
\\
Level:	3\\
Size:	5 MB\\
Type:	Unified cache\\
Associativity:	96\\
Number of sets:	512\\
Cache line size:64\\
Non Inclusive cache\\
Shared among 4 threads\\
\end{multicols}\caption{Saída resumida do likwid-topology}\label{fig:topologyOut}
\end{tt}
\end{figure}

Como pode-se notar na figura~\ref{fig:topologyOut}, nas servidoras do DInf, há
uma CPU Magny Cours, fabricada pela AMD, com 4 socket e 32 cores (8 por socket).

Existem 3 níveis de cache, sendo o primeiro (L1) com 64kB de memória, o segundo
(L2) com 512kB e o terceiro (L3) com 5MB. As caches L1 e L2 são separadas em 32
grupos, sendo que cada grupo é destinado a um core diferente, e o último nível
de cache, L3, é separado em 8 grupos, cada grupo destinado a 4 cores.

Há 8 domínios NUMA, e cada domínio correspondendo a uma cache L3. Como apenas o
Socket 0 será usado, apenas o primeiro domínio NUMA é de interesse para análise
de memória disponivel. O domínio 0 possui 16047.3MB de memória RAM, e no momento
de execução do likwid-topology, havia 10269.2MB de memória livre.

Dada a especificação acima, o maior sistema linear passível de ser resolvido
pela arquitetura descrita é aproximadamente 36600, pois, dada a memória RAM
disponível, e sabendo que o programa aloca $n^2 + 3n$ doubles, temos que $64(n^2 +
3n) = 10269.2\times2^{23}$.

\section{Comparação de desempenho geral}\label{sec:desempenhoGeral}

Para a execução dos testes de desempenho, foi utilizada a ferramenta likwid-pin,
que afixa a execução do programa à um core da máquina em uso dedicado. Mas como
as caches continuam sendo compartilhadas, o que é possível notar na figura
(likwid-topology -g), analisar o desempenho de diferentes execuções se torna um
problema, pois é necessário minimizar o uso de cache pelos outros programas. A
solução encontrada foi executar o gradSolver em single user mode.

No gráfico~\ref{fig:execucao}, são mostrados os tempos de execução em segundos,
que foram obtidos com a função timestamp, para matrizes de dimensões 32, 256,
1024 e 2048. Na escala horizontal do gráfico, as diferenças entre as potências
de 2 e $2^n+1$ não aparecem claramente. O eixo das abcissas está em escala
logarítmica.

\begin{figure}[htb] \begin{center}
\includegraphics[width=100mm]{img/execucoes.jpg} \end{center}
\caption{Tempo de execução por dimensão da matriz}\label{fig:execucao}
\end{figure}

Em teoria, as execuções do gradSolver com matrizes de dimensões que não são
potência de 2 seriam ligeiramente melhores, por causa de um melhor uso da
associatividade da cache. Porém, isso não pode ser verificado nas execuções para
os tamanhos de cache exibidos acima. Uma melhor visualização dos tempos de
execução pode ser observado na tabela~\ref{fig:tabelaExecucoes}, onde a primeira
coluna são as dimensões da matriz e a segunda os tempos de execução em segundos.

\begin{figure}[htb]
\begin{tt}\noindent
    32      0.00014233589172363\\
    33      0.00027585029602051\\
    256     0.00672078132629395\\
    257     0.00610208511352539\\
    1024    0.10956859588623047\\
    1025    0.10990786552429199\\
    2048    0.43970751762390137\\
    2049    0.43948912620544434\\
\end{tt}\caption{Tempo de execução por dimensão da matriz}\label{fig:tabelaExecucoes}
\end{figure}

\section{Análise dos cálculos do fator lambda e resíduo}\label{sec:lambdaResiduo}

\subsection{Medidas de operações em ponto flutuante, memória utilizada e cache
misses}\label{sec:FlopsMemCache}

Utilizando a ferramenta likwid-perfctr, foi possível obter informações nos
trechos de código referentes ao cálculo do fator lambda e do resíduo sobre
memória, cache e operações em ponto flutuante de dupla precisão.

Nos gráficos, nas figuras~\ref{fig:cacheMiss}, ~\ref{fig:usoMem} e
~\ref{fig:flops}, podem ser observadas as taxas de cache miss, MBytes/s e
MFlops/s, respectivamente, de uma iteração do cálculo de lambda, cálculo do
resíduo e as versões de lambda e resíduo com compilação otimizada com -O3 em
relação às dimensões da matriz.

\begin{figure}[htb] \begin{center}
\includegraphics[width=100mm]{img/cacheMiss.jpg} \end{center}
\caption{Taxa de cache miss por dimensão da matriz}\label{fig:cacheMiss}
\end{figure}

Faz sentido que o gráfico na figura~\ref{fig:cacheMiss} mostre que a taxa de
cache miss aumentou na compilação otimizada, pois.

\begin{figure}[htb] \begin{center}
\includegraphics[width=100mm]{img/memUse.jpg} \end{center}
\caption{Uso de memória em MBytes/s por dimensão da matriz}\label{fig:usoMem}
\end{figure}

De maneira análoga, o uso de memória aumenta nas versões otimizadas, pois...

\begin{figure}[htb] \begin{center}
\includegraphics[width=100mm]{img/flops.jpg} \end{center}
\caption{MFlops/s por dimensão da matriz}\label{fig:flops}
\end{figure}

Também...

\subsection{Total de operação em ponto flutuante de dupla
precisão}\label{sec:flopOp}

Na função multMat, há duas operações em ponto flutuante dentro de dois
aninhados, e as duas operações são uma soma e multiplicação juntas, de forma que
é possível que se conte apenas uma operação. Na função multVet, há duas
operações de doubles dentro de apenas um laço. Como a função lambda usa duas
vezes a função multVet e uma vez a função multMat, flops em função de n é,
aproximadamente, f(n) = $n^2 + 2n$, o que pode variar com a otimização do
compilador.

Para obter os valores a partir do likwid, se usa likwid-perfctr medindo o grupo
FLOPS\_DP, pega-se o valor em MFlops/s, multiplica-se pelo tempo em segundos, no
caso o Runtime unhalted, e por $2^{20}$ e aí se obtém o total absoluto de flops.

Não foi possível fazer um casamento da complexidade em função da dimensão da
matriz com a conta que se faz com os valores do likwid, pois saída do
likwid-perfctr para FLOPS\_DP sofre muitas variações. Aí seria necessário ler a
documentação da ferramenta  para descobrir se o programa pega os valores por
amostragem de código em execução. Se isso for assumido, os valores ficam mais
próximos aos reais a partir de uma amostragem de código maior, e no caso
apresentado, somente é levado em consideração uma iteração do cálculo do lambda.

A mesma coisa vale para o cálculo do resíduo, que tem complexidade quadrática.

%\subsection{Utilização de memória}\label{sec:utilizacaoMemoria}
%
%No gráfico ref , vê-se que a uso de memória aumenta em função de
%N. Na função lambda, é usada uma vez a função multMat e duas vezes a função
%multVet, e sabendo que a função multMat tem $3n^2$ (dois laços com 3 acessos
%dentro deles) acessos à memória e a função multVet tem 2n (um laço com dois
%acessos) acessos à memória. Sendo assim, a função de acesso à memória é
%aproximadamente f(n) = $3n^2$ + 4n, sem contar os imprevistos que podem vir a
%occorrer durante a execução do programa, como acessos feitos por programas
%paralelos.
%
%
\end{document}
